{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Llama on Docker\n",
    "\n",
    "This guide will walk you through the steps to set up **OLlama** on Docker.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Prerequisites](#prerequisites)\n",
    "2. [Running OLlama on Docker](#running-llama-on-docker)\n",
    "3. [Basic Troubleshooting](#basic-troubleshooting)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure you have Docker desktop installed\n",
    "\n",
    "- **Docker**: [Docker Installation Guide](https://docs.docker.com/get-started/get-docker/)\n",
    "\n",
    "Make sure Docker is up and running by checking:\n",
    "\n",
    "``` bash\n",
    "docker --version\n",
    "```\n",
    "\n",
    "## Running OLlama on Docker\n",
    "\n",
    "Follow the steps below:\n",
    "\n",
    "1. Create external volumes for ollama and openwebui.\n",
    "\n",
    "    ```\n",
    "    docker volume create ollama-data\n",
    "    docker volume create open-webui-data\n",
    "    \n",
    "    ```\n",
    "2. Run docker compose to start the containers.\n",
    "\n",
    "    ```\n",
    "    docker compose up -d\n",
    "\n",
    "    ```\n",
    "\n",
    "This will host two containers. Ollama on localhost:11434 and open-webui on localhost:8080. \n",
    "\n",
    "![Containers](docker-containers.png)\n",
    "\n",
    "3. Click the highligted links from docker desktop to see the containers are running without any issue. The ollama link should say \"Ollama is running\" and the Webui will open up in browser and ask for admin signup. Follow the instructions on screen and you should be good to go.\n",
    "\n",
    "![signup](openwebui-signup.PNG)\n",
    "\n",
    "4. Initially there will be no models to select from dropdown. Run the following command in ollama container cli.\n",
    "```bash\n",
    "    ollama pull tinyllama\n",
    "```\n",
    "\n",
    "5. Restart the containers\n",
    "```bash\n",
    "    docker compose down\n",
    "    docker compose up -d\n",
    "```\n",
    "\n",
    "6. Login to Web Ui and start chatting\n",
    "\n",
    "![start](openwebui.png)\n",
    "\n",
    "\n",
    "## Basic Troubleshooting\n",
    "\n",
    "##### tinyllama doesn't show up on web ui.\n",
    "    Check if both containers are on same network and able to talk to each other\n",
    "    Check if ollama url env variable is correct\n",
    "    Check if tinyllama is loaded correctly on ollama container\n",
    "        \n",
    "```bash\n",
    "    ollama list\n",
    "```\n",
    "    follow the setps mentioned in the setup\n",
    "\n",
    "    check if curl works from host machine\n",
    "    \n",
    "```bash\n",
    "    curl -X POST http://localhost:11434/api/generate \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\"model\": \"tinyllama\", \"prompt\": \"What are birds?\"}'\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
