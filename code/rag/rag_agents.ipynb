{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG Agents with LangChain and LLMs locally\n",
    "\n",
    "Welcome to a series of blog posts where we explore **LangChain** and **RAG (Retrieval-Augmented Generation)** agents. In this series, you’ll learn how to set up a local LLM (Large Language Model), use LangChain for effective prompt management, and build powerful RAG agents for natural language processing tasks.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to LangChain and RAG](#introduction-to-langchain-and-rag)\n",
    "2. [Setting Up a Local LLM](#setting-up-a-local-llm)\n",
    "3. [Simple Prompt and model chain](#simple-prompt-and-model-chain)\n",
    "4. [Setup Vector DB](#setup-vector-db)\n",
    "5. [Building a Basic RAG Agent using arxiv papers](#building-a-basic-rag-agent)\n",
    "6. [Different chunking techniques](#different-chunking-techniques)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to LangChain and RAG\n",
    "\n",
    "I will not write a post on this as there are lots of resources available on web. [langchain](https://python.langchain.com/docs/introduction/)\n",
    "\n",
    "---\n",
    "\n",
    "## Setting Up a Local LLM\n",
    "\n",
    "In this post, we'll walk through the process of setting up a local LLM using Docker and using it for LangChain-based applications. We’ll use **Ollama** for this demonstration, but the steps are similar for other LLMs.\n",
    "\n",
    "### Key Steps:\n",
    "- Installing Docker and setting up the LLM container.\n",
    "- Interacting with LLM via API.\n",
    "- Testing your local LLM for basic text generation tasks.\n",
    "\n",
    "**Python file**: [llamma_setup](https://github.com/Kunal627/kunal627.github.io/blob/main/code/rag/llamma_setup.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Simple Prompt and model chain\n",
    "\n",
    "Learn how to create a custom LLM wrapper for TinyLlama using LangChain, build a prompt and LLM chain, and run it locally\n",
    "\n",
    "### Key Steps:\n",
    "- Custom LLM wrapper implementation\n",
    "- prompt the tinyllama model and get a response\n",
    "\n",
    "**Python file**: [tinyllama_docker](https://github.com/Kunal627/kunal627.github.io/blob/main/code/rag/tinyllama_docker.ipynb)\n",
    "\n",
    "\n",
    "## Setup Vector DB\n",
    "\n",
    "Learn how to setup Qdrant (vector databse) locally with docker\n",
    "\n",
    "### Key Steps:\n",
    "- Update the docker compose file to bring up qdrant container in docker\n",
    "- test Qdrant setup by running some examples \n",
    "- All the examples are taken (from)[https://qdrant.tech/documentation/beginner-tutorials/]\n",
    "\n",
    "**Python file**: [vecdb_setup](https://github.com/Kunal627/kunal627.github.io/blob/main/code/rag/vecdb_setup.ipynb)\n",
    "\n",
    "\n",
    "## Building a Basic RAG Agent using arxiv papers\n",
    "\n",
    "Build a simple RAG agent using Lang Chain to anwswer questions on arxiv papers\n",
    "\n",
    "### Key Steps:\n",
    "- Download papers from arxiv \n",
    "- Extract text from pdfs, preprocess and chunk the documents\n",
    "- Generate embeddings for the chunks and insert into Vector db\n",
    "- Invoke a tinyllama chain with a prompt\n",
    "\n",
    "**Python file**: [arxiv.ipynb](https://github.com/Kunal627/kunal627.github.io/blob/main/code/rag/demo1/readme.md)\n",
    "\n",
    "\n",
    "## Different chunking techniques\n",
    "\n",
    "Different chunking techniques and pros/cons\n",
    "\n",
    "**Python file**: [chunking.ipynb](https://github.com/Kunal627/kunal627.github.io/blob/main/code/rag/chunking.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
