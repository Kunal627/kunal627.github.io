{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Set up parameters for diffusion\n",
    "timesteps = 10  # Number of diffusion steps\n",
    "beta_start = .0001  # Small amount of initial noise\n",
    "beta_end = .2   # Final amount of noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e-04, 2.2311e-02, 4.4522e-02, 6.6733e-02, 8.8944e-02, 1.1116e-01,\n",
      "        1.3337e-01, 1.5558e-01, 1.7779e-01, 2.0000e-01])\n",
      "torch.Size([10])\n",
      "tensor([0.9999, 0.9777, 0.9555, 0.9333, 0.9111, 0.8888, 0.8666, 0.8444, 0.8222,\n",
      "        0.8000])\n",
      "torch.Size([10])\n",
      "tensor([0.9999, 0.9776, 0.9341, 0.8717, 0.7942, 0.7059, 0.6118, 0.5166, 0.4247,\n",
      "        0.3398])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Create a linear schedule for beta values (variance of noise added at each step)\n",
    "betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "print(betas)\n",
    "print(betas.shape)\n",
    "# Calculate alpha values based on betas\n",
    "alphas = 1.0 - betas\n",
    "print(alphas)\n",
    "print(alphas.shape)\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "print(alphas_cumprod)\n",
    "print(alphas_cumprod.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9999]]]])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "tensor([[[[0.0100]]]])\n",
      "torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "y = torch.sqrt(alphas_cumprod[0]).view(-1,1,1,1)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "y1 = torch.sqrt(1 - alphas_cumprod[0]).view(-1,1,1,1)\n",
    "print(y1)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8800, 0.9200, 0.3800, 0.9600],\n",
      "          [0.3900, 0.6000, 0.2600, 0.7900],\n",
      "          [0.9400, 0.1300, 0.9300, 0.5900],\n",
      "          [0.8700, 0.5700, 0.7400, 0.4300]],\n",
      "\n",
      "         [[0.8900, 0.5700, 0.2700, 0.6300],\n",
      "          [0.2700, 0.4400, 0.3000, 0.8300],\n",
      "          [0.1100, 0.2700, 0.3600, 0.2000],\n",
      "          [0.5500, 0.0100, 0.9500, 0.0800]],\n",
      "\n",
      "         [[0.8900, 0.5800, 0.3400, 0.8100],\n",
      "          [0.5800, 0.9000, 0.5500, 0.3400],\n",
      "          [0.6300, 0.3600, 0.7100, 0.9500],\n",
      "          [0.7900, 0.2800, 0.7900, 0.5900]]],\n",
      "\n",
      "\n",
      "        [[[0.7500, 0.2000, 0.0100, 0.3100],\n",
      "          [0.1200, 0.9100, 0.6400, 0.7100],\n",
      "          [0.6600, 0.4900, 0.8900, 0.1400],\n",
      "          [0.5300, 0.1600, 0.6500, 0.3300]],\n",
      "\n",
      "         [[0.6500, 0.4000, 0.9100, 0.2000],\n",
      "          [0.2000, 0.2000, 0.9500, 0.6700],\n",
      "          [0.9800, 0.0900, 0.0000, 0.1100],\n",
      "          [0.1600, 0.7000, 0.6800, 0.9200]],\n",
      "\n",
      "         [[0.2400, 0.1600, 0.7700, 0.3000],\n",
      "          [0.8000, 0.3800, 0.7900, 0.1100],\n",
      "          [0.2500, 0.6500, 0.6100, 0.3700],\n",
      "          [0.8000, 0.8400, 0.1400, 0.2300]]]])\n",
      "torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[-2.5100,  0.4900,  0.7800,  0.0300],\n",
      "          [ 0.6400,  0.5800,  1.0700, -0.4500],\n",
      "          [-0.1900,  0.7500,  0.4000,  0.1800],\n",
      "          [ 0.2600,  1.2700, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.4600, -0.1000, -0.6000,  0.4800],\n",
      "          [ 0.7300,  0.0900, -0.3900,  0.5300],\n",
      "          [-0.0100,  0.2400,  0.1300,  0.7600],\n",
      "          [ 1.1000,  0.3400,  0.7200,  0.4100]],\n",
      "\n",
      "         [[ 1.9300,  1.0100, -1.4400, -1.1300],\n",
      "          [-0.1400,  1.6400,  0.6500,  0.5800],\n",
      "          [ 1.1400,  0.0200, -1.8100,  0.9300],\n",
      "          [-0.3800,  1.0300, -0.6900,  0.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.9700,  0.9600,  1.6200,  1.4500],\n",
      "          [ 0.2700, -0.2100, -0.7300,  0.1000],\n",
      "          [ 0.3500,  0.9700, -0.4700,  1.6000],\n",
      "          [-2.4800, -0.4200, -1.2000,  0.8100]],\n",
      "\n",
      "         [[-1.9000,  0.2300,  0.0200, -0.3500],\n",
      "          [ 0.2900, -0.7300,  0.1700, -1.0900],\n",
      "          [-1.6000,  1.3500,  1.2900,  0.0500],\n",
      "          [-1.5500,  0.7600,  0.7800,  2.0300]],\n",
      "\n",
      "         [[ 0.0400,  0.1200, -0.8100, -0.2100],\n",
      "          [-0.9300, -1.5900, -1.1400, -0.5200],\n",
      "          [-0.5200, -1.5000, -1.9300,  0.1300],\n",
      "          [ 1.0200, -0.5600,  0.7000,  0.7100]]]])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "img = torch.round(torch.rand(2, 3, 4, 4), decimals=2)\n",
    "print(img)\n",
    "print(img.shape)\n",
    "\n",
    "noise = torch.round(torch.randn(img.shape), decimals=2)\n",
    "print(noise)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8800, 0.9200, 0.3800, 0.9600],\n",
       "          [0.3900, 0.6000, 0.2600, 0.7900],\n",
       "          [0.9400, 0.1300, 0.9300, 0.5900],\n",
       "          [0.8700, 0.5700, 0.7400, 0.4300]],\n",
       "\n",
       "         [[0.8900, 0.5700, 0.2700, 0.6300],\n",
       "          [0.2700, 0.4400, 0.3000, 0.8300],\n",
       "          [0.1100, 0.2700, 0.3600, 0.2000],\n",
       "          [0.5500, 0.0100, 0.9500, 0.0800]],\n",
       "\n",
       "         [[0.8900, 0.5800, 0.3400, 0.8100],\n",
       "          [0.5800, 0.9000, 0.5500, 0.3400],\n",
       "          [0.6300, 0.3600, 0.7100, 0.9500],\n",
       "          [0.7900, 0.2800, 0.7900, 0.5900]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000]]]])\n",
      "torch.Size([2, 1, 1, 1])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0880, 0.0920, 0.0380, 0.0960],\n",
       "          [0.0390, 0.0600, 0.0260, 0.0790],\n",
       "          [0.0940, 0.0130, 0.0930, 0.0590],\n",
       "          [0.0870, 0.0570, 0.0740, 0.0430]],\n",
       "\n",
       "         [[0.0890, 0.0570, 0.0270, 0.0630],\n",
       "          [0.0270, 0.0440, 0.0300, 0.0830],\n",
       "          [0.0110, 0.0270, 0.0360, 0.0200],\n",
       "          [0.0550, 0.0010, 0.0950, 0.0080]],\n",
       "\n",
       "         [[0.0890, 0.0580, 0.0340, 0.0810],\n",
       "          [0.0580, 0.0900, 0.0550, 0.0340],\n",
       "          [0.0630, 0.0360, 0.0710, 0.0950],\n",
       "          [0.0790, 0.0280, 0.0790, 0.0590]]],\n",
       "\n",
       "\n",
       "        [[[0.3750, 0.1000, 0.0050, 0.1550],\n",
       "          [0.0600, 0.4550, 0.3200, 0.3550],\n",
       "          [0.3300, 0.2450, 0.4450, 0.0700],\n",
       "          [0.2650, 0.0800, 0.3250, 0.1650]],\n",
       "\n",
       "         [[0.3250, 0.2000, 0.4550, 0.1000],\n",
       "          [0.1000, 0.1000, 0.4750, 0.3350],\n",
       "          [0.4900, 0.0450, 0.0000, 0.0550],\n",
       "          [0.0800, 0.3500, 0.3400, 0.4600]],\n",
       "\n",
       "         [[0.1200, 0.0800, 0.3850, 0.1500],\n",
       "          [0.4000, 0.1900, 0.3950, 0.0550],\n",
       "          [0.1250, 0.3250, 0.3050, 0.1850],\n",
       "          [0.4000, 0.4200, 0.0700, 0.1150]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.1, .5]).view(-1,1,1,1)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(img.shape)\n",
    "t * img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for sampling Gaussian noise\n",
    "def sample_gaussian_noise(shape):\n",
    "    return torch.randn(shape)\n",
    "\n",
    "# Forward diffusion sampling function\n",
    "def forward_diffusion_sample(x_0, t):\n",
    "    \"\"\"\n",
    "    Add noise to the input image x_0 at time step t.\n",
    "    \n",
    "    Parameters:\n",
    "        x_0: Original image (batch of images)\n",
    "        t: Time step (0 <= t < timesteps)\n",
    "        \n",
    "    Returns:\n",
    "        Noisy image x_t\n",
    "    \"\"\"\n",
    "     # Calculate scaling factors for original image and noise\n",
    "    sqrt_alpha_cumprod_t = torch.sqrt(alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "    noise = sample_gaussian_noise(x_0.shape)\n",
    "\n",
    "    # Generate noisy image\n",
    "    x_t = sqrt_alpha_cumprod_t * x_0 + sqrt_one_minus_alpha_cumprod_t * noise\n",
    "    return x_t, noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
