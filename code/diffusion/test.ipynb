{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Set up parameters for diffusion\n",
    "timesteps = 10  # Number of diffusion steps\n",
    "beta_start = .0001  # Small amount of initial noise\n",
    "beta_end = .2   # Final amount of noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e-04, 2.2311e-02, 4.4522e-02, 6.6733e-02, 8.8944e-02, 1.1116e-01,\n",
      "        1.3337e-01, 1.5558e-01, 1.7779e-01, 2.0000e-01])\n",
      "torch.Size([10])\n",
      "tensor([0.9999, 0.9777, 0.9555, 0.9333, 0.9111, 0.8888, 0.8666, 0.8444, 0.8222,\n",
      "        0.8000])\n",
      "torch.Size([10])\n",
      "tensor([0.9999, 0.9776, 0.9341, 0.8717, 0.7942, 0.7059, 0.6118, 0.5166, 0.4247,\n",
      "        0.3398])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Create a linear schedule for beta values (variance of noise added at each step)\n",
    "betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "print(betas)\n",
    "print(betas.shape)\n",
    "# Calculate alpha values based on betas\n",
    "alphas = 1.0 - betas\n",
    "print(alphas)\n",
    "print(alphas.shape)\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "print(alphas_cumprod)\n",
    "print(alphas_cumprod.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9999]]]])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "tensor([[[[0.0100]]]])\n",
      "torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "y = torch.sqrt(alphas_cumprod[0]).view(-1,1,1,1)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "y1 = torch.sqrt(1 - alphas_cumprod[0]).view(-1,1,1,1)\n",
    "print(y1)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8800, 0.9200, 0.3800, 0.9600],\n",
      "          [0.3900, 0.6000, 0.2600, 0.7900],\n",
      "          [0.9400, 0.1300, 0.9300, 0.5900],\n",
      "          [0.8700, 0.5700, 0.7400, 0.4300]],\n",
      "\n",
      "         [[0.8900, 0.5700, 0.2700, 0.6300],\n",
      "          [0.2700, 0.4400, 0.3000, 0.8300],\n",
      "          [0.1100, 0.2700, 0.3600, 0.2000],\n",
      "          [0.5500, 0.0100, 0.9500, 0.0800]],\n",
      "\n",
      "         [[0.8900, 0.5800, 0.3400, 0.8100],\n",
      "          [0.5800, 0.9000, 0.5500, 0.3400],\n",
      "          [0.6300, 0.3600, 0.7100, 0.9500],\n",
      "          [0.7900, 0.2800, 0.7900, 0.5900]]],\n",
      "\n",
      "\n",
      "        [[[0.7500, 0.2000, 0.0100, 0.3100],\n",
      "          [0.1200, 0.9100, 0.6400, 0.7100],\n",
      "          [0.6600, 0.4900, 0.8900, 0.1400],\n",
      "          [0.5300, 0.1600, 0.6500, 0.3300]],\n",
      "\n",
      "         [[0.6500, 0.4000, 0.9100, 0.2000],\n",
      "          [0.2000, 0.2000, 0.9500, 0.6700],\n",
      "          [0.9800, 0.0900, 0.0000, 0.1100],\n",
      "          [0.1600, 0.7000, 0.6800, 0.9200]],\n",
      "\n",
      "         [[0.2400, 0.1600, 0.7700, 0.3000],\n",
      "          [0.8000, 0.3800, 0.7900, 0.1100],\n",
      "          [0.2500, 0.6500, 0.6100, 0.3700],\n",
      "          [0.8000, 0.8400, 0.1400, 0.2300]]]])\n",
      "torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[-2.5100,  0.4900,  0.7800,  0.0300],\n",
      "          [ 0.6400,  0.5800,  1.0700, -0.4500],\n",
      "          [-0.1900,  0.7500,  0.4000,  0.1800],\n",
      "          [ 0.2600,  1.2700, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.4600, -0.1000, -0.6000,  0.4800],\n",
      "          [ 0.7300,  0.0900, -0.3900,  0.5300],\n",
      "          [-0.0100,  0.2400,  0.1300,  0.7600],\n",
      "          [ 1.1000,  0.3400,  0.7200,  0.4100]],\n",
      "\n",
      "         [[ 1.9300,  1.0100, -1.4400, -1.1300],\n",
      "          [-0.1400,  1.6400,  0.6500,  0.5800],\n",
      "          [ 1.1400,  0.0200, -1.8100,  0.9300],\n",
      "          [-0.3800,  1.0300, -0.6900,  0.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.9700,  0.9600,  1.6200,  1.4500],\n",
      "          [ 0.2700, -0.2100, -0.7300,  0.1000],\n",
      "          [ 0.3500,  0.9700, -0.4700,  1.6000],\n",
      "          [-2.4800, -0.4200, -1.2000,  0.8100]],\n",
      "\n",
      "         [[-1.9000,  0.2300,  0.0200, -0.3500],\n",
      "          [ 0.2900, -0.7300,  0.1700, -1.0900],\n",
      "          [-1.6000,  1.3500,  1.2900,  0.0500],\n",
      "          [-1.5500,  0.7600,  0.7800,  2.0300]],\n",
      "\n",
      "         [[ 0.0400,  0.1200, -0.8100, -0.2100],\n",
      "          [-0.9300, -1.5900, -1.1400, -0.5200],\n",
      "          [-0.5200, -1.5000, -1.9300,  0.1300],\n",
      "          [ 1.0200, -0.5600,  0.7000,  0.7100]]]])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "img = torch.round(torch.rand(2, 3, 4, 4), decimals=2)\n",
    "print(img)\n",
    "print(img.shape)\n",
    "\n",
    "noise = torch.round(torch.randn(img.shape), decimals=2)\n",
    "print(noise)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8800, 0.9200, 0.3800, 0.9600],\n",
       "          [0.3900, 0.6000, 0.2600, 0.7900],\n",
       "          [0.9400, 0.1300, 0.9300, 0.5900],\n",
       "          [0.8700, 0.5700, 0.7400, 0.4300]],\n",
       "\n",
       "         [[0.8900, 0.5700, 0.2700, 0.6300],\n",
       "          [0.2700, 0.4400, 0.3000, 0.8300],\n",
       "          [0.1100, 0.2700, 0.3600, 0.2000],\n",
       "          [0.5500, 0.0100, 0.9500, 0.0800]],\n",
       "\n",
       "         [[0.8900, 0.5800, 0.3400, 0.8100],\n",
       "          [0.5800, 0.9000, 0.5500, 0.3400],\n",
       "          [0.6300, 0.3600, 0.7100, 0.9500],\n",
       "          [0.7900, 0.2800, 0.7900, 0.5900]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000]]]])\n",
      "torch.Size([2, 1, 1, 1])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0880, 0.0920, 0.0380, 0.0960],\n",
       "          [0.0390, 0.0600, 0.0260, 0.0790],\n",
       "          [0.0940, 0.0130, 0.0930, 0.0590],\n",
       "          [0.0870, 0.0570, 0.0740, 0.0430]],\n",
       "\n",
       "         [[0.0890, 0.0570, 0.0270, 0.0630],\n",
       "          [0.0270, 0.0440, 0.0300, 0.0830],\n",
       "          [0.0110, 0.0270, 0.0360, 0.0200],\n",
       "          [0.0550, 0.0010, 0.0950, 0.0080]],\n",
       "\n",
       "         [[0.0890, 0.0580, 0.0340, 0.0810],\n",
       "          [0.0580, 0.0900, 0.0550, 0.0340],\n",
       "          [0.0630, 0.0360, 0.0710, 0.0950],\n",
       "          [0.0790, 0.0280, 0.0790, 0.0590]]],\n",
       "\n",
       "\n",
       "        [[[0.3750, 0.1000, 0.0050, 0.1550],\n",
       "          [0.0600, 0.4550, 0.3200, 0.3550],\n",
       "          [0.3300, 0.2450, 0.4450, 0.0700],\n",
       "          [0.2650, 0.0800, 0.3250, 0.1650]],\n",
       "\n",
       "         [[0.3250, 0.2000, 0.4550, 0.1000],\n",
       "          [0.1000, 0.1000, 0.4750, 0.3350],\n",
       "          [0.4900, 0.0450, 0.0000, 0.0550],\n",
       "          [0.0800, 0.3500, 0.3400, 0.4600]],\n",
       "\n",
       "         [[0.1200, 0.0800, 0.3850, 0.1500],\n",
       "          [0.4000, 0.1900, 0.3950, 0.0550],\n",
       "          [0.1250, 0.3250, 0.3050, 0.1850],\n",
       "          [0.4000, 0.4200, 0.0700, 0.1150]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.1, .5]).view(-1,1,1,1)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(img.shape)\n",
    "t * img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for sampling Gaussian noise\n",
    "def sample_gaussian_noise(shape):\n",
    "    return torch.randn(shape)\n",
    "\n",
    "# Forward diffusion sampling function\n",
    "def forward_diffusion_sample(x_0, t):\n",
    "    \"\"\"\n",
    "    Add noise to the input image x_0 at time step t.\n",
    "    \n",
    "    Parameters:\n",
    "        x_0: Original image (batch of images)\n",
    "        t: Time step (0 <= t < timesteps)\n",
    "        \n",
    "    Returns:\n",
    "        Noisy image x_t\n",
    "    \"\"\"\n",
    "     # Calculate scaling factors for original image and noise\n",
    "    sqrt_alpha_cumprod_t = torch.sqrt(alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "    noise = sample_gaussian_noise(x_0.shape)\n",
    "\n",
    "    # Generate noisy image\n",
    "    x_t = sqrt_alpha_cumprod_t * x_0 + sqrt_one_minus_alpha_cumprod_t * noise\n",
    "    return x_t, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def sinusoidal_embedding(timesteps, embedding_dim, theta=10000.0):\n",
    "    \"\"\"\n",
    "    Generate sinusoidal embeddings for the given timesteps.\n",
    "\n",
    "    Args:\n",
    "        timesteps (torch.Tensor): A tensor of shape (batch_size,) containing integer timestep values.\n",
    "        embedding_dim (int): The dimension of the embedding.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (batch_size, embedding_dim) containing the sinusoidal embeddings.\n",
    "    \"\"\"\n",
    "    embed_idx = torch.arange(0, embedding_dim // 2, dtype=torch.float32)\n",
    "    base = theta ** (2 * embed_idx / embedding_dim)\n",
    "\n",
    "    input = timesteps / base\n",
    "\n",
    "    embeddings = torch.cat([torch.sin(input), torch.cos(input)], dim=1)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.gn1 = nn.GroupNorm(2, out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.gn2 = nn.GroupNorm(2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.gelu(self.gn1(self.conv1(x)))\n",
    "        out = F.gelu(self.gn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, embedding_dim=32, pool=False):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.convblk1 = ConvBlock(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.convblk2 = ConvBlock(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.tsembed  = nn.Linear(embedding_dim, out_channels)\n",
    "        self.pool = pool\n",
    "\n",
    "    def forward(self, x, t=None):\n",
    "        if self.pool:\n",
    "            x = self.maxpool(x)\n",
    "        out = self.convblk1(x)\n",
    "        out = self.convblk2(out)\n",
    "        \n",
    "        # add timestep embedding\n",
    "        if t is None:\n",
    "            tsembed = F.silu(self.tsembed(t))\n",
    "            tsembed = tsembed[:, :, None, None]\n",
    "            out += tsembed\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, stride=2):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.gn1 = nn.GroupNorm(2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.gelu(self.gn1(self.conv1(x)))\n",
    "        return out\n",
    "    \n",
    "class DiffModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, embedding_dim=64):\n",
    "        super(DiffModel, self).__init__()\n",
    "        \n",
    "        self.enc1 = DownSampleBlock(in_channels, 64)\n",
    "        self.enc2 = DownSampleBlock(64, 128, pool=True)\n",
    "        self.enc3 = DownSampleBlock(128, 256, pool=True)\n",
    "        self.enc4 = DownSampleBlock(256, 512, pool=True)\n",
    "        \n",
    "        self.bottleneck = DownSampleBlock(512, 1024, pool=True)\n",
    "        \n",
    "        self.upconv4 = UpSampleBlock(1024, 512)\n",
    "        self.dec4 = ConvBlock(1024, 512)\n",
    "        \n",
    "        self.upconv3 = UpSampleBlock(512, 256)\n",
    "        self.dec3 = ConvBlock(512, 256)\n",
    "        \n",
    "        self.upconv2 = UpSampleBlock(256, 128)\n",
    "        self.dec2 = ConvBlock(256, 128)\n",
    "        \n",
    "        self.upconv1 = UpSampleBlock(128, 64)\n",
    "        self.dec1 = ConvBlock(128, 64)\n",
    "        \n",
    "        self.final_layer = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, t=None):\n",
    "        e1 = self.enc1(x, t)\n",
    "        e2 = self.enc2(e1, t)\n",
    "        e3 = self.enc3(e2, t)\n",
    "        e4 = self.enc4(e3, t)\n",
    "\n",
    "        bottleneck = self.bottleneck(e4, t)\n",
    "               \n",
    "        up4 = self.upconv4(bottleneck)\n",
    "        up4 = torch.cat((e4, up4), dim=1)\n",
    "        d4 = self.dec4(up4)\n",
    "        \n",
    "        up3 = self.upconv3(d4)\n",
    "        up3 = torch.cat((e3, up3), dim=1)\n",
    "        d3 = self.dec3(up3)\n",
    "        \n",
    "        up2 = self.upconv2(d3)\n",
    "        up2 = torch.cat((e2, up2), dim=1)\n",
    "        d2 = self.dec2(up2)\n",
    "        \n",
    "        up1 = self.upconv1(d2)\n",
    "        up1 = torch.cat((e1, up1), dim=1)\n",
    "        d1 = self.dec1(up1)\n",
    "\n",
    "        return self.final_layer(d1)\n",
    "    \n",
    "moodel = DiffModel()\n",
    "img = torch.rand(2, 3, 32, 32)\n",
    "y = moodel(img, torch.Tensor([0.1, .5]))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 32, 32])\n",
      "torch.Size([2, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img = torch.rand(2, 3, 32, 32)\n",
    "conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "gn1 = nn.GroupNorm(2, 16)\n",
    "x1 = conv1(img)\n",
    "print(x1.shape)\n",
    "x2 = F.gelu(gn1(x1))\n",
    "print(x2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
