{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Generative Adversarial Networks (GANs)\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a class of machine learning models introduced by Ian Goodfellow in 2014, designed to generate realistic synthetic data by using two neural networks: a generator and a discriminator. The generator creates fake data, such as images, from random noise, while the discriminator evaluates whether the data is real (from the training set) or fake (produced by the generator).\n",
    "\n",
    "These networks compete in a min-max game: the generator tries to fool the discriminator by producing increasingly realistic data, while the discriminator gets better at distinguishing real from fake. This adversarial training helps the generator learn to create highly realistic outputs.\n",
    "\n",
    "GANs have found applications in various fields, including image generation, style transfer, super-resolution, and data augmentation. However, they can be challenging to train due to issues like mode collapse and training instability, requiring careful tuning of hyperparameters and architectures.\n",
    "\n",
    "Despite these challenges, GANs remain one of the most popular techniques for generative tasks due to their ability to produce high-quality outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Convolutional GAN (DCGAN)\n",
    "Deep Convolutional GAN (DCGAN) is an extension of the original GAN architecture that utilizes convolutional neural networks to improve the quality of generated images. Introduced by Alec Radford, Luke Metz, and Soumith Chintala in 2015, DCGAN replaces the fully connected layers used in traditional GANs with convolutional and transposed convolutional layers, making it particularly effective for image generation tasks.\n",
    "\n",
    "The generator in DCGAN uses transposed convolutions to upsample the latent noise vector into high-resolution images, while the discriminator applies convolutions to classify images as real or fake. Key techniques like batch normalization and Leaky ReLU activation help stabilize training and prevent issues like mode collapse.\n",
    "\n",
    "DCGAN has been influential in advancing image generation, serving as a foundation for more sophisticated architectures like StyleGAN and CycleGAN. Its ability to leverage convolutional structures makes it ideal for tasks such as image synthesis, super-resolution, and artistic style transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN vs DCGAN\n",
    "\n",
    "| Aspect                        | GAN                                         | DCGAN                                     |\n",
    "|-------------------------------|---------------------------------------------|-------------------------------------------|\n",
    "| **Architecture**              | Fully connected layers (MLPs)               | Convolutional layers (Conv2d, ConvTranspose2d) |\n",
    "| **Spatial Awareness**         | No spatial awareness                        | Captures spatial features and hierarchies |\n",
    "| **Generator Upsampling**      | Uses linear layers                          | Uses transposed convolutions              |\n",
    "| **Discriminator**             | Uses linear layers                          | Uses convolutional layers                 |\n",
    "| **Activation Functions**      | Sigmoid/Tanh                                | ReLU in generator, Leaky ReLU in discriminator |\n",
    "| **Normalization**             | Not consistently used                       | Batch normalization in most layers        |\n",
    "| **Training Stability**        | Prone to instability and mode collapse      | More stable, reduced mode collapse        |\n",
    "| **Output**                    | Works with various data types               | Primarily designed for image generation   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "Trained on Intel(R) Core(TM) i7-9850H CPU @ 2.60GHz   2.59 GHz with 24 GB RAM\n",
    "\n",
    "##### 1st Iteration: Trained simple GAN on MNIST with (1 min 20 seconds per epoch)\n",
    "\n",
    "* Constant learning rate of 0.0002 for both discriminator and generator \n",
    "* Batch size = 64\n",
    "* latent dimensions = 100\n",
    "* Weights initialization with Normal distribution\n",
    "\n",
    "![generated images](../images/gan_genupd1_epoch_24.png)\n",
    "![loss](../images/gan_genupd1_losses.png)\n",
    "\n",
    "\n",
    "##### 2nd Iteration: Simple GAN with (1 min 5 sec per epoch)\n",
    "\n",
    "* Batch size=128\n",
    "* Label smoothing to real labels\n",
    "* Adam optimizer with betas=(0.5, 0.999)\n",
    "* Train generator weight updates = 2 times the discriminator\n",
    "* lr for genertaor = 0.0002, discriminator = 0.0001\n",
    "* weight initialization (normal distribution)\n",
    "* latent dims = 256\n",
    "\n",
    "![generated images](../images/gan_genupd2_epoch_16.png)\n",
    "\n",
    "NOTE: iteration1 produced better results than iteration2\n",
    "\n",
    "##### DCGANS  (Time per epoch ~ 11 minutes)\n",
    "\n",
    "* Batch Size 64\n",
    "* Adam optimizer with betas=(0.5, 0.999)\n",
    "* lr = 0.0002 for both discriminator and generator\n",
    "* latent dims = 100\n",
    "\n",
    "![gen and disc losses](../images/final_dcgan_losses.png)\n",
    "![generated images](../images/dcgan_epoch_16.png)\n",
    "\n",
    "##### DCGANS  (Time per Epoch ~ 12 minutes)\n",
    "\n",
    "* Batch Size = 64\n",
    "* latent dims = 100\n",
    "* Train generator weight updates = 2 times the discriminator\n",
    "* Adam optimizer with betas=(0.5, 0.999)\n",
    "* lr for genertaor = 0.0002, discriminator = 0.0001\n",
    "\n",
    "![final dcgan loss](../images/dcgan_genupd2_losses.png)\n",
    "![generated images](../images/dcgan_genupd2_epoch_16.png)\n",
    "\n",
    "\n",
    "The discriminator loss decreasing while the generator loss increases often indicates an imbalance in the training dynamics. The above strategies aim to slow down the discriminator's learning or boost the generator's performance, helping to balance the two networks. Try experimenting with different combinations of these techniques to find the most suitable configuration for your specific GAN model.\n",
    "I couldn't get the generator loss to converge, nevertheless the generated images look ok. I would resort to compute FID scores just in case to see whether the generated images are any good?\n",
    "Stopping my experiments because of paucity of time and compute (for complex datasets). The code for FID calculation is in the repo.\n",
    "\n",
    "##### My observations:\n",
    "\n",
    "* DCGANS started generated better images early during training but the generator loss could not converge. Not a good fit for simple dataset like MNIST \n",
    "* Training Simpla GANs , the generator loss converged but the generated image quality did not improve further\n",
    "* Even though the DCGANs have higher generator loss comapred to GANS, the generated image quality was better. I would go for FID scores than relying purely on loss.\n",
    "\n",
    "Source code ----> https://github.com/Kunal627/kunal627.github.io/tree/main/code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further reading and references\n",
    "\n",
    "* Generative Adversarial Nets - https://arxiv.org/pdf/1406.2661\n",
    "* Unsupervised representation learning with deep convolutional generative adversarial networks - https://arxiv.org/pdf/1511.06434\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
